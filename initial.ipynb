{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'split_folders'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-699765daaae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msplit_folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'split_folders'"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import shap\n",
    "import keras.backend as K\n",
    "import json\n",
    "import split_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_folders.ratio('data/', output=\"output\", seed=1337, ratio=(.8, .2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model and choose two images to explain\n",
    "model = VGG16(weights='imagenet', include_top=True) ## CHANGE INCLUDE TOP TO FALSE\n",
    "X,y = shap.datasets.imagenet50()\n",
    "to_explain = X[[6,7]]\n",
    "\n",
    "# load the ImageNet class names\n",
    "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "fname = shap.datasets.cache(url)\n",
    "with open(fname) as f:\n",
    "    class_names = json.load(f)\n",
    "\n",
    "# explain how the input to the 7th layer of the model explains the top two classes\n",
    "def map2layer(x, layer):\n",
    "    feed_dict = dict(zip([model.layers[0].input], [preprocess_input(x.copy())]))\n",
    "    return K.get_session().run(model.layers[layer].input, feed_dict)\n",
    "e = shap.GradientExplainer((model.layers[7].input, model.layers[-1].output), map2layer(preprocess_input(X.copy()), 7))\n",
    "shap_values,indexes = e.shap_values(map2layer(to_explain, 7), ranked_outputs=2)\n",
    "\n",
    "# get the names for the classes\n",
    "index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n",
    "\n",
    "# plot the explanations\n",
    "shap.image_plot(shap_values, to_explain, index_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.image_plot(shap_values, to_explain, index_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = target_size\n",
    "img_height = target_size\n",
    "batch_size =16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling (we do not want to modify the testing data)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "\n",
    "# The generator object. \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'output/train',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'output/val',\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_last_layer(base_model, nb_classes=14):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "    Args:\n",
    "    base_model: keras model excluding top\n",
    "    nb_classes: # of classes\n",
    "    Returns:\n",
    "    new keras model with last layer\n",
    "    \"\"\"\n",
    "    # Get the output shape of the models last layer\n",
    "    x = base_model.output\n",
    "    # Convert final MxNxC tensor output into a 1xC tensor where C is the # of channels.\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x) \n",
    "    x = Dropout(.5)(x)\n",
    "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will freeze the weights on all the layers except for our new dense layer\n",
    "def setup_to_transfer_learn(model, base_model):\n",
    "  \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "  for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "  model.compile(optimizer=optimizers.SGD(lr=0.0001, momentum=0.9),    \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(target_size,target_size,3))\n",
    "\n",
    "tran_model = add_new_last_layer(base_model)\n",
    "setup_to_transfer_learn(tran_model,base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_epoch = 3\n",
    "\n",
    "tran_model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=nb_epoch,\n",
    "    steps_per_epoch=100,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('output/val/boxer/1485179194-boxer-dog-portrait.jpg',target_size=(target_size,target_size) )\n",
    "img = img_to_array(img)\n",
    "img = img.reshape((1,) + img.shape)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tran_model.predict(img)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(pred, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model and choose two images to explain\n",
    "# model = VGG16(weights='imagenet', include_top=True) ## CHANGE INCLUDE TOP TO FALSE\n",
    "model = tran_model\n",
    "# X,y = shap.datasets.imagenet50()\n",
    "img = load_img('output/val/boxer/1485179194-boxer-dog-portrait.jpg',target_size=(224,224) )\n",
    "img = img_to_array(img)\n",
    "img = img.reshape((1,) + img.shape)\n",
    "to_explain = img\n",
    "X = img\n",
    "\n",
    "# # load the ImageNet class names\n",
    "# url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "# fname = shap.datasets.cache(url)\n",
    "# with open(fname) as f:\n",
    "#     class_names = json.load(f)\n",
    "class_names = labels\n",
    "\n",
    "# explain how the input to the 7th layer of the model explains the top two classes\n",
    "def map2layer(x, layer):\n",
    "    feed_dict = dict(zip([model.layers[0].input], [preprocess_input(x.copy())]))\n",
    "    return K.get_session().run(model.layers[layer].input, feed_dict)\n",
    "\n",
    "e = shap.GradientExplainer((model.layers[7].input, model.layers[-1].output), map2layer(preprocess_input(X.copy()), 7))\n",
    "shap_values,indexes = e.shap_values(map2layer(to_explain, 7), ranked_outputs=2)\n",
    "\n",
    "# get the names for the classes\n",
    "index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n",
    "\n",
    "# plot the explanations\n",
    "shap.image_plot(shap_values, to_explain, index_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.get_session().run(model.layers[layer].input, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
